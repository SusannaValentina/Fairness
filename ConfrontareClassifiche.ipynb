{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNrK6jvEZQsjo836UnOFEef",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SusannaValentina/Fairness/blob/master/ConfrontareClassifiche.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoRiLPcviC_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def RBO(l1, l2, p):\n",
        "    \"\"\"\n",
        "        Calculates Ranked Biased Overlap (RBO) score. \n",
        "        l1 -- Ranked List 1\n",
        "        l2 -- Ranked List 2\n",
        "    \"\"\"\n",
        "    if l1 == None: l1 = []\n",
        "    if l2 == None: l2 = []\n",
        "    \n",
        "    sl,ll = sorted([(len(l1), l1),(len(l2),l2)])\n",
        "    s, S = sl # s = length of smaller list, S = Smaller List\n",
        "    l, L = ll # l = length of longer list, L = Longer list\n",
        "    if s == 0: return 0\n",
        "\n",
        "    # Calculate the overlaps at ranks 1 through l \n",
        "    # (the longer of the two lists)\n",
        "    ss = set([]) # contains elements from the smaller list till depth i\n",
        "    ls = set([]) # contains elements from the longer list till depth i\n",
        "    x_d = {0: 0} # overlap holds number of common elements at depth d\n",
        "    sum1 = 0.0\n",
        "    for i in range(l):\n",
        "        x = L[i]\n",
        "        y = S[i] if i < s else None\n",
        "        d = i + 1\n",
        "        \n",
        "        # if two elements are same then \n",
        "        # we don't need to add to either of the set\n",
        "        if x == y: \n",
        "            x_d[d] = x_d[d-1] + 1.0\n",
        "        # else add items to respective list\n",
        "        # and calculate overlap\n",
        "        else: \n",
        "            ls.add(x) \n",
        "            if y != None: ss.add(y)\n",
        "            x_d[d] = x_d[d-1] + (1.0 if x in ss else 0.0) + (1.0 if y in ls else 0.0)     \n",
        "        #calculate average overlap\n",
        "        sum1 += x_d[d]/d * pow(p, d)\n",
        "        \n",
        "    sum2 = 0.0\n",
        "    for i in range(l-s):\n",
        "        d = s+i+1\n",
        "        sum2 += x_d[d]*(d-s)/(d*s)*pow(p,d)\n",
        "\n",
        "    sum3 = ((x_d[l]-x_d[s])/l+x_d[s]/s)*pow(p,l)\n",
        "\n",
        "    # Equation 32\n",
        "    rbo_ext = (1-p)/p*(sum1+sum2)+sum3\n",
        "    return rbo_ext"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZZXcpQIhqDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from scipy.stats._stats import _kendall_dis\n",
        "from math import sqrt, fsum\n",
        "from operator import itemgetter\n",
        "from itertools import combinations, permutations\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats\n",
        "\n",
        "def prova (xs,ys):\n",
        "# Calculate the rank of x's\n",
        "  xranks = pd.Series(xs).rank()\n",
        "    \n",
        "# Caclulate the ranking of the y's\n",
        "  yranks = pd.Series(ys).rank()\n",
        "    \n",
        "# Calculate Pearson's correlation coefficient on the ranked versions of the data\n",
        "  print(scipy.stats.pearsonr(xranks, yranks))\n",
        "\n",
        "  return scipy.stats.spearmanr(xs, ys)\n",
        "\n",
        "def _mean(m):\n",
        "    return fsum(m) / len(m)\n",
        "\n",
        "\n",
        "def _fancy(m):\n",
        "    a = sum(m)\n",
        "    b = 0\n",
        "    for i in m:\n",
        "        b += i * i\n",
        "    return len(m) * b - (a ** 2)\n",
        "\n",
        "\n",
        "def _rank(m):\n",
        "    (ivec, svec) = zip(*sorted(list(enumerate(m)), key=itemgetter(1)))\n",
        "    sumranks = 0\n",
        "    dupcount = 0\n",
        "    newlist = [0] * len(m)\n",
        "    for i in range(len(m)):\n",
        "        sumranks += i\n",
        "        dupcount += 1\n",
        "        if i == len(m) - 1 or svec[i] != svec[i + 1]:\n",
        "            averank = sumranks / float(dupcount) + 1\n",
        "            for j in range(i - dupcount + 1, i + 1):\n",
        "                newlist[ivec[j]] = averank\n",
        "            sumranks = 0\n",
        "            dupcount = 0\n",
        "    return newlist\n",
        "\n",
        "\n",
        "def _concordance(m, n):\n",
        "    \"\"\" \n",
        "    returns count of concordant, discordant, and tied pairs\n",
        "    \"\"\"\n",
        "    if len(m) != len(n):\n",
        "        raise ValueError #, 'Iterables (m, n) must be the same length'\n",
        "    c = 0\n",
        "    d = 0\n",
        "    iss = 0\n",
        "    for (i, j) in combinations(range(len(m)), 2):\n",
        "        m_dir = m[i] - m[j]\n",
        "        n_dir = n[i] - n[j]\n",
        "        sign = m_dir * n_dir\n",
        "        if sign: # not a tie\n",
        "            c += 1\n",
        "            d += 1\n",
        "            if sign > 0:\n",
        "                iss += 1\n",
        "            elif sign < 0:\n",
        "                iss -= 1\n",
        "        else:\n",
        "            if m_dir:\n",
        "                c += 1\n",
        "            elif n_dir:\n",
        "                d += 1\n",
        "            # else is a tie in both ways and of no concern to us\n",
        "    return (c, d, iss)\n",
        "\n",
        "\n",
        "## USER FUNCTIONS\n",
        "\n",
        "def pearson_rho(m, n):\n",
        "    \"\"\" \n",
        "    return the Pearson rho coefficient; based off stats.py \n",
        "    >>> x = [2, 8, 5, 4, 2, 6, 1, 4, 5, 7, 4]\n",
        "    >>> y = [3, 9, 4, 3, 1, 7, 2, 5, 6, 8, 3]\n",
        "    >>> pearson_rho(x, y)\n",
        "    0.9245404356092288\n",
        "    \"\"\"\n",
        "    if len(m) != len(n):\n",
        "        raise ValueError #, 'Iterables (m, n) must be the same length'\n",
        "    num = len(m) * (sum([i * j for i, j in zip(m, n)])) - sum(m) * sum(n)\n",
        "    return num / sqrt(_fancy(m) * _fancy(n))\n",
        "\n",
        "\n",
        "def spearman_rho(m, n):\n",
        "    \"\"\" \n",
        "    return Spearman's rho; based off stats.py \n",
        "    >>> x = [2, 8, 5, 4, 2, 6, 1, 4, 5, 7, 4]\n",
        "    >>> y = [3, 9, 4, 3, 1, 7, 2, 5, 6, 8, 3]\n",
        "    >>> spearman_rho(x, y)\n",
        "    0.9363636363636364\n",
        "    \"\"\"\n",
        "    if len(m) != len(n):\n",
        "        raise ValueError #, 'Iterables (m, n) must be the same length'\n",
        "    dsq = sum([(mi - ni) ** 2 for (mi, ni) in zip(_rank(m), _rank(n))])\n",
        "    return 1. - 6. * dsq / float(len(m) * (len(n) ** 2 - 1.))\n",
        "\n",
        "\n",
        "def spearman_rho_tr(m, n):\n",
        "    \"\"\" \n",
        "    rho for tied ranks, checked by comparison with Pycluster\n",
        "    >>> x = [2, 8, 5, 4, 2, 6, 1, 4, 5, 7, 4]\n",
        "    >>> y = [3, 9, 4, 3, 1, 7, 2, 5, 6, 8, 3]\n",
        "    >>> spearman_rho_tr(x, y)\n",
        "    0.9348938334114621\n",
        "    \"\"\"\n",
        "    m = _rank(m)\n",
        "    n = _rank(n)\n",
        "    num = 0.\n",
        "    den_m = 0.\n",
        "    den_n = 0.\n",
        "    m_mean = _mean(m)\n",
        "    n_mean = _mean(n) \n",
        "    for (i, j) in zip(m, n):\n",
        "        i = i - m_mean\n",
        "        j = j - n_mean\n",
        "        num += i * j \n",
        "        den_m += i ** 2\n",
        "        den_n += j ** 2\n",
        "    return num / sqrt(den_m * den_n)\n",
        "\n",
        "\n",
        "def goodman_kruskal_gamma(m, n):\n",
        "    \"\"\" \n",
        "    compute the Goodman and Kruskal gamma rank correlation coefficient; \n",
        "    this statistic ignores ties is unsuitable when the number of ties in the\n",
        "    data is high. it's also slow. \n",
        "    >>> x = [2, 8, 5, 4, 2, 6, 1, 4, 5, 7, 4]\n",
        "    >>> y = [3, 9, 4, 3, 1, 7, 2, 5, 6, 8, 3]\n",
        "    >>> goodman_kruskal_gamma(x, y)\n",
        "    0.9166666666666666\n",
        "    \"\"\"\n",
        "    num = 0\n",
        "    den = 0\n",
        "    for (i, j) in permutations(range(len(m)), 2):\n",
        "        m_dir = m[i] - m[j]\n",
        "        n_dir = n[i] - n[j]\n",
        "        sign = m_dir * n_dir\n",
        "        if sign > 0:\n",
        "            num += 1\n",
        "            den += 1\n",
        "        elif sign < 0:\n",
        "            num -= 1\n",
        "            den += 1\n",
        "    return num / float(den)\n",
        "\n",
        "\n",
        "def kendall_tau_b(m, n):\n",
        "    \"\"\" \n",
        "    compute Kendall's rank correlation coefficient tau_b; based on stats.py,\n",
        "    but fixes a major bug in that code (as well as the scipy implementation); \n",
        "    the results returned here accord with STATA/SPSS/SAS/R \n",
        "    >>> x = [2, 8, 5, 4, 2, 6, 1, 4, 5, 7, 4]\n",
        "    >>> y = [3, 9, 4, 3, 1, 7, 2, 5, 6, 8, 3]\n",
        "    >>> kendall_tau_b(x, y)\n",
        "    0.8629109946080097\n",
        "    \"\"\"\n",
        "    (c, d, iss) = _concordance(m, n)\n",
        "    return iss / sqrt(c * d)\n",
        "\n",
        "\n",
        "def kendall_tau_c(m, n):\n",
        "    \"\"\" \n",
        "    compute Kendall's rank correlation coefficient tau_c\n",
        "    >>> x = [2, 8, 5, 4, 2, 6, 1, 4, 5, 7, 4]\n",
        "    >>> y = [3, 9, 4, 3, 1, 7, 2, 5, 6, 8, 3]\n",
        "    >>> kendall_tau_c(x, y)\n",
        "    0.8484848484848485\n",
        "    \"\"\"\n",
        "    (c , d, iss) = _concordance(m, n)\n",
        "    min_dim = min(len(set(m)), len(set(n)))\n",
        "    return (2. * min_dim * iss) / ((min_dim - 1) * len(m) ** 2)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    from doctest import testmod\n",
        "    testmod()\n",
        "\n",
        "\n",
        "\n",
        "# import data\n",
        "#df_ = pd.read_csv('Data/CR_mockData_EAD.csv')\n",
        "#df = df_[['realized_ead', 'pred_value']][0:100]\n",
        "\n",
        "def SomersD(x, y):\n",
        "\n",
        "    x = np.asarray(x).ravel()\n",
        "    y = np.asarray(y).ravel()\n",
        "\n",
        "    if x.size != y.size:\n",
        "        raise ValueError(\"All inputs must be of the same size, \"\n",
        "                         \"found x-size %s and y-size %s\" % (x.size, y.size))\n",
        "\n",
        "    def count_rank_tie(ranks):\n",
        "        cnt = np.bincount(ranks).astype('int64', copy=False)\n",
        "        cnt = cnt[cnt > 1]\n",
        "        return ((cnt * (cnt - 1) // 2).sum(),\n",
        "            (cnt * (cnt - 1.) * (cnt - 2)).sum(),\n",
        "            (cnt * (cnt - 1.) * (2*cnt + 5)).sum())\n",
        "\n",
        "    size = x.size\n",
        "    perm = np.argsort(y)  # sort on y and convert y to dense ranks\n",
        "    x, y = x[perm], y[perm]\n",
        "    y = np.r_[True, y[1:] != y[:-1]].cumsum(dtype=np.intp)\n",
        "\n",
        "    # stable sort on x and convert x to dense ranks\n",
        "    perm = np.argsort(x, kind='mergesort')\n",
        "    x, y = x[perm], y[perm]\n",
        "    x = np.r_[True, x[1:] != x[:-1]].cumsum(dtype=np.intp)\n",
        "\n",
        "    dis = _kendall_dis(x, y)  # discordant pairs\n",
        "\n",
        "    obs = np.r_[True, (x[1:] != x[:-1]) | (y[1:] != y[:-1]), True]\n",
        "    cnt = np.diff(np.where(obs)[0]).astype('int64', copy=False)\n",
        "\n",
        "    ntie = (cnt * (cnt - 1) // 2).sum()  # joint ties\n",
        "    xtie, x0, x1 = count_rank_tie(x)     # ties in x, stats\n",
        "    ytie, y0, y1 = count_rank_tie(y)     # ties in y, stats\n",
        "\n",
        "    tot = (size * (size - 1)) // 2\n",
        "\n",
        "    # Note that tot = con + dis + (xtie - ntie) + (ytie - ntie) + ntie\n",
        "    #               = con + dis + xtie + ytie - ntie\n",
        "    #con_minus_dis = tot - xtie - ytie + ntie - 2 * dis\n",
        "    SD = (tot - xtie - ytie + ntie - 2 * dis) / (tot - ntie)\n",
        "    return (SD, dis)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def score(l1, l2, depth = 10):\n",
        "    \"\"\"\n",
        "        Calculates Average Overlap score. \n",
        "        l1 -- Ranked List 1\n",
        "        l2 -- Ranked List 2\n",
        "        depth -- depth\n",
        "    \"\"\"\n",
        "    if l1 == None: l1 = []\n",
        "    if l2 == None: l2 = []\n",
        "\n",
        "    sl, ll = sorted([(len(l1), l1),(len(l2),l2)])\n",
        "    s, S = sl  # s = length of smaller list, S = Smaller List\n",
        "    l, L = ll  # l = length of longer list, L = Longer list\n",
        "    #sanity check\n",
        "    if s == 0: return 0\n",
        "    depth = depth if depth < l else l\n",
        "    \n",
        "    # Calculate fraction of overlap from rank  at ranks 1 through depth\n",
        "    # (the longer of the two lists)\n",
        "    ss = set([])\n",
        "    ls = set([])\n",
        "    overlap = {0: 0}  # overlap holds number of common elements at depth d \n",
        "    sum1 = 0.0  \n",
        "\n",
        "    for i in range(depth):\n",
        "        # get elements from the two list\n",
        "        x = L[i]\n",
        "        y = S[i] if i < s else None\n",
        "        depth = i+1\n",
        "        # if the two elements are same, then we don't need\n",
        "        # to them to the list and just increment the \n",
        "        if x == y: \n",
        "            overlap[depth] = overlap[i] + 2\n",
        "        #else add items to the two list\n",
        "        else:\n",
        "            ls.add(x)\n",
        "            if y != None: ss.add(y)\n",
        "            overlap[depth] = overlap[i] + (2 if x in ss else 0) + (2 if y in ls else 0) \n",
        "        sum1 = sum1 + float(overlap[depth])/(len(S[0:depth]) + depth)\n",
        "\n",
        "    return sum1/depth\n",
        "\n",
        "    \n",
        "#start_time = time.time()\n",
        "#SD, dis = SomersD(df.realized_ead, df.pred_value)\n",
        "#print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bU5zmFmh_kw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import auth\n",
        "import json\n",
        "\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "Restaurant_Info = '15LwpZqBUvtbuePS-7K0ezRtfUecInjx9'\n",
        "download = drive.CreateFile({'id': Restaurant_Info})\n",
        "download.GetContentFile('Tupelo Honey_date_desc.csv')\n",
        "\n",
        "Restaurant_RBO = '1aOTHWSNdkjzW7EyyaomdXxgnzjXdqN7S'\n",
        "download = drive.CreateFile({'id': Restaurant_RBO})\n",
        "download.GetContentFile('Tupelo Honey_relevance_desc.csv')\n",
        "\n",
        "with open('Tupelo Honey_date_desc.csv') as data:\n",
        "    csv_reader = csv.reader(data, delimiter=',')\n",
        "    line_count = 0\n",
        "    a = []\n",
        "    for riga in csv_reader:\n",
        "      #se è l'header vai alla riga successiva\n",
        "      if(line_count <= 0):\n",
        "        line_count = line_count + 1\n",
        "      else:\n",
        "        a.append(riga[0])\n",
        "\n",
        "with open('Tupelo Honey_relevance_desc.csv') as yelp:\n",
        "    csv_reader = csv.reader(yelp, delimiter=',')\n",
        "    line_count = 0\n",
        "    b = []\n",
        "    for riga in csv_reader:\n",
        "      #se è l'header vai alla riga successiva\n",
        "      if(line_count <= 0):\n",
        "        line_count = line_count + 1\n",
        "      else:\n",
        "        b.append(riga[0])\n",
        "        \n",
        "\n",
        "c = [2, 8, 2, 4, 1, 6, 1, 4, 5, 7, 4]\n",
        "d = [1, 3, 5, 6, 1, 6, 1, 4, 5, 7, 4]\n",
        "\n",
        "#print(pearson_rho(a,b))\n",
        "#print(spearman_rho(a,b))\n",
        "print(spearman_rho_tr(a,b))\n",
        "print(score(a,b))\n",
        "print(RBO(a,b,0.93))\n",
        "#print(prova(a,b))\n",
        "#print(goodman_kruskal_gamma(a,b))\n",
        "#print(kendall_tau_b(a,b))\n",
        "#print(kendall_tau_c(a,b))\n",
        "#print(SomersD(a,b)[0])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}